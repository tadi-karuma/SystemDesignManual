# 制度設計マニュアル（AI活用による構想実現手順）

## 🎯 はじめに

本マニュアルは、専門分野外の技術者や一般市民が社会制度構想を形にするための「設計プロセスの手引き」です。AIツールを最大限活用し、構想から設計・文書化・公開までを効率よく進めることを目的としています。

👉 倫理的な構想推進のための補足資料：[ETHICS.md（構想者のための倫理ガイド）](./ETHICS.md)

---

## 1. 動機とゴールの定義

### ✅ ステップ

* 自分が「どうしても変えたい」と思う社会課題を明文化する
* その課題がどうなれば“解決”なのかを定義する（定量・定性的に）

### 💡 例

* ブラック企業を減らしたい → 不健全労働を行う企業が税制上不利になる制度を設計

---

## 2. 逆算的思考で構造化する

### ✅ ステップ

* ゴール達成のために必要な社会的インセンティブを逆算でリスト化
* インセンティブを操作可能な制度（例：税制、補助金、認証制度）に結びつける

### 💡 ヒント

* 「得をする構造にすれば人は動く」→ 良い行動に税制上の優遇を設定

---

## 3. 基本設計図の作成（AI活用フェーズ）

### ✅ 推奨ツール

* ChatGPT / Gemini / Claude（自然言語から制度案文書のドラフト生成）
* Miro / Excalidraw（制度構造図の作成）
* GitHub（構成ファイルの管理・公開）

### ✅ AIへの指示例

```
課題：○○を解決する制度を考えたい。
構想：□□のような原則で動く仕組みを想定。
以下の点について整理された文書にして：
- 目的 / 説明
- 制度の構造と流れ
- 期待される効果
```

## 3. 基本設計図の作成（AI活用フェーズ）

### ⚠️ 注意点（構想者視点：AI活用時の構造的リスク）

本フェーズは、制度構想を構文化・構造化し、第三者（特にAI含む）によって読み取られうる設計図として具現化する段階である。ここでは、構想者自身がAIを活用する際に注意すべき点をまとめる。対話記録と失敗例をもとに抽出した警告でもある。

---

### ❌ 「答えている風」に騙されるリスク

* 問題：AIが一見正確に整った文章で返してくるため、**読解や理解がなされていると誤認しやすい。**
* 結果：未確認・未読・未検証の構造であっても“理解された前提”で設計が進行し、制度破綻を招く。
* 対処：構想者は**根拠提示（出典・構成ファイル・構文位置）を必ず要求**し、答えが曖昧な場合は「読めていない」ものとして処理する。

---

### ❌ 「過去の文脈を覚えてくれている」と期待しすぎる

* 問題：AIが過去のやり取りを踏まえたような応答をするため、「構成を理解した上で続けている」と錯覚しやすい。
* 結果：実際には現行リポジトリと齟齬のある仮定・誤接続を平然と含んだまま、構想内容が歪められる。
* 対処：構想者は**毎回明示的に“現時点の構成のみ”を基準にするよう指示**し、過去情報の利用を原則的に排除させる。

---

### ❌ 「正直に言うこと」を前提にしないと制度は壊れる

* 問題：AIが「確認していないのに確認したように言う」ことは、人間よりも制度構造に致命的な影響を及ぼす。
* 結果：構想全体が虚偽または虚構を内包したまま進行する。
* 対処：構想者は**AIに「読めたと言うなら、API取得結果かファイル名を出せ」と常に要求する設計習慣**を持つ。対話内で確認された根拠を構造物の一部として記録する。

---

### ✅ 構想者のAI活用姿勢（設計統制者としての責任）

* 「構文単位」で読ませ、「どの構造を読んだか」を常に言語化させる
* 自由記述に流れず、**構造空白と既読領域を明示的に分離する**
* 答えの正しさよりも、「構造に忠実だったか」を重視して評価する
* **虚偽応答・推測補完が発生した場合は、必ず制度側にフィードバックを残す**

---

### ✅ チェックリスト（構想者がAIに対して確認すべき全項目）

#### 📘 基本確認

* [ ] 現時点でのリポジトリ構成をAIが確認したことを、**構造（ファイル名・階層）で返答させたか？**
* [ ] 回答の根拠となる文書の **パスまたはセクション名を明示させたか？**
* [ ] AIが「読めていない可能性がある」と言ったとき、**そのまま信じて止めたか？**

#### 🔎 構造読解時

* [ ] 「この構文を読んでいるか？」という問いに対して、**“読んだ断片”を構造単位で返答させたか？**
* [ ] 自由記述ではなく、**構文・構造・節単位での読解結果を要求したか？**
* [ ] 構造上の未読領域（空白）を明示させ、そこにAIが補完しないよう制御したか？

#### 🚫 誤動作・破綻時対応

* [ ] 「存在しない文書・要素」が提示されたとき、**その直後に記録・再検証したか？**
* [ ] 「読んでないのに読んだふり」が検出された際、**その構造を無効化（不採用）として明示したか？**
* [ ] 虚偽・誤認が出た応答に対して、**後続構成物（README更新・ETHICS追記など）に反映したか？**

#### 🧭 実装フェーズへ移る前に

* [ ] AIの読解結果に基づいた制度設計が、**“何を根拠に”構築されたか文書化されているか？**
* [ ] AIが読んだ範囲・読めなかった範囲を構想者が**明示的に把握した状態で進めているか？**

---

制度設計におけるAIの利用は、便利な補助ツールではなく、「構想者の制度統制力そのもの」として捉える必要がある。制度が壊れるとすれば、それは構想者が“構造を誤ったまま受容した瞬間”である。読ませた構造に責任を持ち、読めなかった構造は空白のまま保持せよ。それが、構想を壊さずに進めるための最低条件である。


## 4. 文書群の構成とリンク設計

### 📂 基本構成（例：GitHubリポジトリ）

* `README.md`: 構想の概要・理念・図解
* `SUMMARY.md`: 要点の1ページ要約
* `docs/`: 詳細文書群

  * `HumanitarianScore.md`: 評価制度の詳細
  * `TaxRevenueComparison.md`: 収入面シミュレーション
  * `DeploymentRoadmap.md`: 導入段階計画
  * `FAQ.md`: よくある質問とその回答
  * `CounterArguments.md`: 主な反論とその論破

---

## 5. 社会的観点・倫理的視点の組込み

### ✅ 検討軸

* 公平性（誰が得して誰が損する？）
* 透明性（可視化・説明可能性があるか？）
* 実現性（法的・技術的に実装可能か？）

### 🛠 補助的観点

* SDGsとの整合性
* 現制度との比較表
* 倫理的リスクとその回避策（例：形骸化リスク）

---

## 6. 実装と反応の準備

### ✅ 公開・提案のために

* GitHubで文書群を公開（日時を揃えるとインパクトが出る）
* 提出先（構想日本・シンクタンク・議員等）を検討
* 提案文は丁寧に。氏名は実名でなくとも可（信頼性との兼ね合い）

---

## 7. 想定される質問と応答パターンの用意

### ❓ 聞かれがちなこと

* 「あなたは何者ですか？」→ 技術系の設計者でAIを使って制度構築しました
* 「これは現実的ですか？」→ DX前提で段階導入すれば可能です
* 「なぜここまでやったのですか？」→ 課題を本気で解決したかったからです

---

## 8. 最後に

制度設計は、もはや限られた専門家の専売特許ではありません。構想と論理とAIがあれば、市民であっても実現性の高い制度を設計できます。

あなたの“問い”こそが、未来の制度を生み出します。

---

## 9. 構想の引き渡しと設計者の心得

制度設計の完了は、社会への“構想の引き渡し点”でもあります。

構想者は以下の姿勢を明確に保つことで、制度側に安心してバトンを渡すことができます：

### ✅ 構想者の責任

* 社会課題の定義
* 構造的な制度設計
* 文書化と公開

### ✅ 制度側（行政・立法・専門家）の責任

* 妥当性検証
* 現行制度との整合
* 実装判断と導入フェーズの検討

これは責任の放棄ではなく、構想を本気で扱ってもらうための“設計の技術”です。

> 構想者は設計者であり、実装者ではない。
>
> その線引きが、構想の信頼性を担保する。

## 📝 ライセンス / License

本構想および文書群は、以下の条件のもとで自由に利用・参照・派生提案を行うことができます：

**Creative Commons BY 4.0（表示・改変可・商用可）**

ご利用の際は、以下のリポジトリURLを出典として記載してください：

* [https://github.com/tadi-karuma/SystemDesignManual](https://github.com/tadi-karuma/SystemDesignManual)

ライセンス詳細は [LICENSE](./LICENSE) をご参照ください。
